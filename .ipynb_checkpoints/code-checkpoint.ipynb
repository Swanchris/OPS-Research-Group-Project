{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\mathcal{l}_2$ penalty method algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def alpha(k): return 2**k\n",
    "# def xplus(x): return max(x,0)\n",
    "# def Norm(x): return np.linalg.norm(x)\n",
    "\n",
    "# def obj_func(x): return x[0]**2 + x[1]**2 + x[0] - x[1]\n",
    "# def G(x): return np.array([1 -x[0], -x[1] ])\n",
    "# def P(x,k): return obj_func(x) + (alpha(k)/2)*xplus(G(x)[0])**2 + (alpha(k)/2)*xplus(G(x)[1])**2\n",
    "# def P_grad(x,k):\n",
    "#     g1 = 2*x[0] + 1 - alpha(k)*xplus(1-x[0])\n",
    "#     g2 = 2*x[1] - 1 - alpha(k)*xplus(-x[1])\n",
    "#     return np.array( [ g1 , g2 ] )\n",
    "# def stepsize(x1, x0,k): # Barzilai-Borwein step-size (quasi-newton origin)\n",
    "#     nom = np.dot(x1 - x0, P_grad(x1,k) - P_grad(x0,k))\n",
    "#     denom = np.linalg.norm( P_grad(x1,k) - P_grad(x0,k) )**2\n",
    "#     return nom/denom\n",
    "# # Note: Direction is just steepest descent\n",
    "# def GD(x, lam ,k):\n",
    "#     return x - lam*P_grad(x,k)\n",
    "# def Descent(x, init_step, EPSILON):\n",
    "#     x0 = np.array(x)\n",
    "#     k = 1\n",
    "#     x_list = [x0]\n",
    "#     lam = init_step\n",
    "#     x1 = GD(x0, lam ,k)\n",
    "#     x_list.append(x1)\n",
    "#     N = Norm(x1 - x0)\n",
    "#     Norm_list = [N]\n",
    "    \n",
    "#     while N > EPSILON:\n",
    "#         lam = stepsize(x1, x0, k)\n",
    "#         x0 = x1\n",
    "#         x1 = GD(x0, lam, k)\n",
    "#         x_list.append(x1)\n",
    "#         N = Norm(x1 - x0)\n",
    "#         Norm_list = [N]\n",
    "#         k += 1\n",
    "    \n",
    "#     return np.array([ x_list, Norm_list ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The real deal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(k): return 2**k\n",
    "def xplus(x): return max(x,0)\n",
    "def Norm(x): return np.linalg.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIELDSIZE = 100\n",
    "SCALE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate a squared norm of s - x, as in our obj func and constraints\n",
    "def norm_func(s, x):\n",
    "    return (s[0] - x[0])**2 + (s[1] - x[1])**2\n",
    "\n",
    "# create a list of the squared euclidean distance from s to each point x in X\n",
    "def X_norms_sqrd(s, X): return [norm_func(s,i) for i in X]\n",
    "\n",
    "# find the largest distance\n",
    "def beta(s, X): return max(X_norms_sqrd(s, X))\n",
    "\n",
    "# create an objective function\n",
    "def obj_func(s,X): \n",
    "    x_list = X_norms_sqrd(s,X)\n",
    "    return sum(x_list) + beta(s, x_list)\n",
    "\n",
    "# create the g constraints\n",
    "def G(s,X): return [ norm_func(s, X[i]) - beta(s, X) for i in range(len(X))]\n",
    "\n",
    "# l2-penalty function\n",
    "def P(s,X,k): \n",
    "    return obj_func(s,X) + (alpha(k)/2)*sum([ xplus(G(s,X)[i])**2 for i in range(len(X)) ])\n",
    "\n",
    "def P_grad(s,X,k):\n",
    "    s_minus_x_0 = np.array([ s[0] - X[i][0] for i in range(len(X)) ])\n",
    "    G_sum_0 = np.array([ (s[0] - X[i][0])**2 - beta(s, X) for i in range(len(X))])\n",
    "    mult_terms_0 = [xplus(s_minus_x_0[i] * G_sum_0[i]) for i in range(len(X))]\n",
    "    \n",
    "    g1 = 2*sum(s_minus_x_0) + 2*alpha(k)*sum( mult_terms_0)\n",
    "    \n",
    "    s_minus_x_1 = np.array([ s[1] - X[i][1] for i in range(len(X)) ])\n",
    "    G_sum_1 = np.array([ (s[1] - X[i][1])**2 - beta(s, X) for i in range(len(X))])\n",
    "    mult_terms_1 = [xplus(s_minus_x_1[i] * G_sum_1[i]) for i in range(len(X))]\n",
    "    \n",
    "    g2 = 2*sum(s_minus_x_1) + 2*alpha(k)*sum( mult_terms_1)\n",
    "    \n",
    "    return np.array( [g1 , g2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepsize(s1, s0, X, k): # Barzilai-Borwein step-size (quasi-newton origin)\n",
    "    nom = np.dot(s1 - s0, P_grad(s1, X ,k) - P_grad(s0, X ,k))\n",
    "    denom = np.linalg.norm( P_grad(s1, X ,k) - P_grad(s0, X ,k) )**2\n",
    "    return nom/denom\n",
    "# Note: Direction is just steepest descent\n",
    "def GD(s, X, lam ,k):\n",
    "    return s - lam*P_grad(s, X ,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate FIELDSIZE random pts in R^2 \\in (0,SCALE)\n",
    "X_points = [ [ random.random()*SCALE, random.random()*SCALE ] for i in range(FIELDSIZE) ] \n",
    "\n",
    "# generate an inital point S in the plain of X\n",
    "S_0 = [ random.random()*SCALE, random.random()*SCALE ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Descent(s, X, init_step, EPSILON):\n",
    "    s0 = np.array(s)\n",
    "    k = 1\n",
    "    s_list = [s0]\n",
    "    lam = init_step\n",
    "    s1 = GD(s0, X, lam ,k)\n",
    "    s_list.append(s1)\n",
    "    N = Norm(s1 - s0)\n",
    "    Norm_list = [N]\n",
    "    \n",
    "    while N > EPSILON:\n",
    "        lam = stepsize(s1, s0, X, k)\n",
    "        s0 = s1\n",
    "        s1 = GD(s0, X, lam, k)\n",
    "        s_list.append(s1)\n",
    "        N = Norm(s1 - s0)\n",
    "        Norm_list.append(N)\n",
    "        k += 1\n",
    "    \n",
    "    return np.array([ s_list, Norm_list ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-16b2525321ec>:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array([ s_list, Norm_list ])\n"
     ]
    }
   ],
   "source": [
    "TEST = Descent( np.array([5,5]), X_points, 0.1, 1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[289.60201268 302.57110591]\n"
     ]
    }
   ],
   "source": [
    "print(TEST[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26231599.808139157, 26220755.08237924, 434.4169358012732, 540434.7417428873, 91.40619208161395, 13.834040004556542, 17.160525858133468, 7.731030762644693, 4.355693218671689, 2.9459038982690946, 2.0246780174445864, 1.0725811000319398, 1.6276969496643832, 0.9271242232199771, 1.1641532238204633e-08, 543813.8167882726, 539741.2599191816, 6.086952384818681e-05, 521607.5479410597, 412829.4254896868, 3.2495460866101817, 412835.1929198333, 412711.9853192845, 0.411136687440629, 412712.39643917297, 412712.49922357366, 0.051392219488660226, 412712.55098621297, 412712.56383399165, 0.006423889855474694, 412712.5659234104, 412712.56752973725, 0.0008031894372825425, 412712.4849643791, 412712.4851465792, 0.00010088893120376416, 412712.62351481774, 412712.62348663405, 1.2509692690456872e-05, 412712.7818157869, 412712.7817531323, 1.5493583941899982e-06, 412716.4323330333, 412716.04397087754, 1.5735538705710108e-07, 412359.743378515, 352.44077734030327, 352.44045705370473, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(TEST[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([5, 5]),\n",
       " array([-18813303.61418309, -18279936.12358874]),\n",
       " array([-540913.76555511,  525588.76432316]),\n",
       " array([-540479.3486193 ,  525588.76432316]),\n",
       " array([-4.46068764e+01,  5.25588764e+05]),\n",
       " array([4.67993157e+01, 5.25588764e+05]),\n",
       " array([6.06333557e+01, 5.25588764e+05]),\n",
       " array([7.77938815e+01, 5.25588764e+05]),\n",
       " array([8.55249123e+01, 5.25588764e+05]),\n",
       " array([8.98806055e+01, 5.25588764e+05]),\n",
       " array([9.28265094e+01, 5.25588764e+05]),\n",
       " array([9.48511874e+01, 5.25588764e+05]),\n",
       " array([9.59237685e+01, 5.25588764e+05]),\n",
       " array([9.75514655e+01, 5.25588764e+05]),\n",
       " array([9.84785897e+01, 5.25588764e+05]),\n",
       " array([9.84785897e+01, 5.25588764e+05]),\n",
       " array([    45.01809684, -18225.04983659]),\n",
       " array([ 66029.40905911, 517467.6678743 ]),\n",
       " array([ 66029.40906681, 517467.66793468]),\n",
       " array([47.21680164, 50.25000892]),\n",
       " array([291686.16227376, 292240.01717069]),\n",
       " array([291688.45787011, 292242.31712443]),\n",
       " array([46.81436524, 47.09422211]),\n",
       " array([284354.04520799, 299213.5718173 ]),\n",
       " array([284354.32843004, 299213.86984188]),\n",
       " array([46.81437692, 47.09423419]),\n",
       " array([284354.39930672, 299213.9442807 ]),\n",
       " array([284354.43470957, 299213.98153387]),\n",
       " array([46.81412175, 47.09396568]),\n",
       " array([284354.43073489, 299214.00303514]),\n",
       " array([284354.43516015, 299214.00769169]),\n",
       " array([46.81710766, 47.09710765]),\n",
       " array([284354.58640105, 299213.86617868]),\n",
       " array([284354.58695435, 299213.8667609 ]),\n",
       " array([46.87453825, 47.15753977]),\n",
       " array([284357.50104174, 299211.0976346 ]),\n",
       " array([284357.50111124, 299211.09770773]),\n",
       " array([46.77928883, 47.05731299]),\n",
       " array([284352.69743071, 299215.66277606]),\n",
       " array([284352.69743933, 299215.66278513]),\n",
       " array([46.67022962, 46.94255129]),\n",
       " array([284347.35704623, 299220.73769052]),\n",
       " array([284347.3570473 , 299220.73769164]),\n",
       " array([44.15550059, 44.29625951]),\n",
       " array([284757.24776868, 298830.15275561]),\n",
       " array([284757.24776879, 298830.15275572]),\n",
       " array([289.94643652, 302.24378919]),\n",
       " array([46.81436939, 47.09422626]),\n",
       " array([289.60201268, 302.57110591]),\n",
       " array([289.60201268, 302.57110591])]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_ax = [X_points[i][0] for i in range(len(X_points))]\n",
    "y_ax = [X_points[i][1] for i in range(len(X_points))]\n",
    "plt.scatter(x_ax, y_ax, c ='y')\n",
    "plt.scatter(TEST[0][-3][0],TEST[0][-3][1], c = 'b' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([289.60201268, 302.57110591])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48557.52865815, 51095.37592916])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_grad(TEST[0][-1], X_points, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [5 5]\n",
      "Gradient [11  9]\n",
      "stepsize: 0.1\n",
      "x: [3.9 4.1]\n",
      "Gradient [8.8 7.2]\n",
      "Squared Norm: 1.42126704035519\n",
      "stepsize: 0.5000000000000002\n",
      "x: [-0.5  0.5]\n",
      "Gradient [-3.00000000e+00 -3.55271368e-15]\n",
      "k= 2\n",
      "Squared Norm: 5.6850681614207605\n",
      "stepsize: 0.33608978145304175\n",
      "x: [1.51653869 0.5       ]\n",
      "Gradient [ 4.03307738e+00 -1.11022302e-15]\n",
      "k= 3\n",
      "Squared Norm: 2.016538688718255\n",
      "stepsize: 0.1257736516357206\n",
      "x: [1.00928382 0.5       ]\n",
      "Gradient [ 3.01856764e+00 -7.77156117e-16]\n",
      "k= 4\n",
      "Squared Norm: 0.5072548690896048\n",
      "stepsize: 0.5\n",
      "x: [-0.5  0.5]\n",
      "Gradient [-24.   0.]\n",
      "k= 5\n",
      "Squared Norm: 1.509283819628648\n",
      "stepsize: 0.02958303005095145\n",
      "x: [0.91998544 0.5       ]\n",
      "Gradient [0.27950504 0.        ]\n",
      "k= 6\n",
      "Squared Norm: 1.4199854424456697\n",
      "stepsize: 0.015151515151515152\n",
      "x: [0.95454545 0.5       ]\n",
      "Gradient [2.66453526e-15 0.00000000e+00]\n",
      "k= 7\n",
      "Squared Norm: 0.034560012099784876\n",
      "stepsize: 0.007692307692307694\n",
      "x: [0.97692308 0.5       ]\n",
      "Gradient [-3.55271368e-15  0.00000000e+00]\n",
      "k= 8\n",
      "Squared Norm: 0.022377622377622308\n",
      "stepsize: 0.003875968992248062\n",
      "x: [0.98837209 0.5       ]\n",
      "Gradient [-5.32907052e-15  0.00000000e+00]\n",
      "k= 9\n",
      "Squared Norm: 0.0114490161001789\n",
      "stepsize: 0.0019455252918287938\n",
      "x: [0.99416342 0.5       ]\n",
      "Gradient [1.0658141e-14 0.0000000e+00]\n",
      "k= 10\n",
      "Squared Norm: 0.005791331101257846\n",
      "stepsize: 0.0009746588693957116\n",
      "x: [0.99707602 0.5       ]\n",
      "Gradient [2.84217094e-14 0.00000000e+00]\n",
      "k= 11\n",
      "Squared Norm: 0.002912599267299254\n",
      "stepsize: 0.0004878048780487805\n",
      "x: [0.99853659 0.5       ]\n",
      "Gradient [-2.66453526e-15  0.00000000e+00]\n",
      "k= 12\n",
      "Squared Norm: 0.0014605619740407638\n",
      "stepsize: 0.00024402147388970225\n",
      "x: [0.99926794 0.5       ]\n",
      "Gradient [1.70530257e-13 0.00000000e+00]\n",
      "k= 13\n",
      "Squared Norm: 0.0007313502124772775\n",
      "stepsize: 0.000122040517451794\n",
      "x: [0.99963388 0.5       ]\n",
      "Gradient [1.0658141e-14 0.0000000e+00]\n",
      "k= 14\n",
      "Squared Norm: 0.0003659428693136846\n",
      "stepsize: 6.102770657878677e-05\n",
      "x: [0.99981692 0.5       ]\n",
      "Gradient [8.8817842e-16 0.0000000e+00]\n",
      "k= 15\n",
      "Squared Norm: 0.00018303843261902042\n",
      "stepsize: 3.0515715593530668e-05\n",
      "x: [0.99990845 0.5       ]\n",
      "Gradient [-6.82121026e-13  0.00000000e+00]\n",
      "k= 16\n",
      "Squared Norm: 9.153597295574745e-05\n",
      "stepsize: 1.525832341542311e-05\n",
      "x: [0.99995423 0.5       ]\n",
      "Gradient [-8.52651283e-14  0.00000000e+00]\n",
      "k= 17\n",
      "Squared Norm: 4.577217653434218e-05\n",
      "stepsize: 7.629278117704503e-06\n",
      "x: [0.99997711 0.5       ]\n",
      "Gradient [-1.0658141e-14  0.0000000e+00]\n",
      "k= 18\n",
      "Squared Norm: 2.288713589315705e-05\n",
      "stepsize: 3.814668162016586e-06\n",
      "x: [0.99998856 0.5       ]\n",
      "Gradient [-1.33226763e-15  0.00000000e+00]\n",
      "k= 19\n",
      "Squared Norm: 1.1443829867063826e-05\n",
      "stepsize: 1.9073413568826414e-06\n",
      "x: [0.99999428 0.5       ]\n",
      "Gradient [-1.45519152e-11  0.00000000e+00]\n",
      "k= 20\n",
      "Squared Norm: 5.721980415374084e-06\n",
      "stepsize: 9.536724974203157e-07\n",
      "x: [0.99999714 0.5       ]\n",
      "Gradient [1.09139364e-11 0.00000000e+00]\n",
      "k= 21\n",
      "Squared Norm: 2.8610065784251404e-06\n",
      "stepsize: 4.7683670345620785e-07\n",
      "x: [0.99999857 0.5       ]\n",
      "Gradient [2.72848411e-12 0.00000000e+00]\n",
      "k= 22\n",
      "Squared Norm: 1.430507381883217e-06\n",
      "stepsize: 2.38418465414779e-07\n",
      "x: [0.99999928 0.5       ]\n",
      "Gradient [6.82121026e-13 0.00000000e+00]\n",
      "k= 23\n",
      "Squared Norm: 7.15254714123148e-07\n",
      "stepsize: 1.192092611290786e-07\n",
      "x: [0.99999964 0.5       ]\n",
      "Gradient [1.70530257e-13 0.00000000e+00]\n",
      "k= 24\n",
      "Squared Norm: 3.576276128569589e-07\n",
      "stepsize: 5.9604637669964114e-08\n",
      "x: [0.99999982 0.5       ]\n",
      "Gradient [4.26325641e-14 0.00000000e+00]\n",
      "k= 25\n",
      "Squared Norm: 1.7881387037732566e-07\n",
      "stepsize: 2.980232061133858e-08\n",
      "x: [0.99999991 0.5       ]\n",
      "Gradient [1.0658141e-14 0.0000000e+00]\n",
      "k= 26\n",
      "Squared Norm: 8.940695117587438e-08\n",
      "stepsize: 1.4901160749758461e-08\n",
      "x: [0.99999996 0.5       ]\n",
      "Gradient [2.66453526e-15 0.00000000e+00]\n",
      "k= 27\n",
      "Squared Norm: 4.470347958474008e-08\n",
      "stepsize: 7.4505804859015265e-09\n",
      "x: [0.99999998 0.5       ]\n",
      "Gradient [8.8817842e-16 0.0000000e+00]\n",
      "k= 28\n",
      "Squared Norm: 2.2351740791570762e-08\n",
      "stepsize: 3.7252902707063384e-09\n",
      "x: [0.99999999 0.5       ]\n",
      "Gradient [7.4505806e-09 0.0000000e+00]\n",
      "k= 29\n",
      "Squared Norm: 1.1175870673341137e-08\n",
      "stepsize: 1.8626451422920633e-09\n",
      "x: [0.99999999 0.5       ]\n",
      "Gradient [-1.11758709e-08  0.00000000e+00]\n",
      "k= 30\n",
      "Squared Norm: 5.587935336670569e-09\n",
      "stepsize: 9.313225728807549e-10\n",
      "x: [1.  0.5]\n",
      "Gradient [-5.58793545e-09  0.00000000e+00]\n",
      "k= 31\n",
      "Squared Norm: 2.7939677238464355e-09\n",
      "stepsize: 4.656612868740584e-10\n",
      "x: [1.  0.5]\n",
      "Gradient [-2.79396772e-09  0.00000000e+00]\n",
      "k= 32\n",
      "Squared Norm: 1.3969838619232178e-09\n",
      "stepsize: 2.328306435454494e-10\n",
      "x: [1.  0.5]\n",
      "Gradient [-1.39698386e-09  0.00000000e+00]\n",
      "k= 33\n",
      "Squared Norm: 6.984919309616089e-10\n",
      "stepsize: 1.1641532179982976e-10\n",
      "x: [1.  0.5]\n",
      "Gradient [-6.98491931e-10  0.00000000e+00]\n",
      "k= 34\n",
      "Squared Norm: 3.4924596548080444e-10\n",
      "stepsize: 5.8207660906691144e-11\n",
      "x: [1.  0.5]\n",
      "Gradient [-3.49245965e-10  0.00000000e+00]\n",
      "k= 35\n",
      "Squared Norm: 1.7462298274040222e-10\n",
      "stepsize: 2.9103830455039638e-11\n",
      "x: [1.  0.5]\n",
      "Gradient [-1.74622983e-10  0.00000000e+00]\n",
      "k= 36\n",
      "Squared Norm: 8.731149137020111e-11\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([5,5])\n",
    "EPSILON = 1e-10\n",
    "k = 1\n",
    "# x0 = np.array([random.randrange(1,20), random.randrange(0,20)])\n",
    "print(\"x:\", x0)\n",
    "print(\"Gradient\", P_grad(x0,k))\n",
    "lam = 0.1 #random.random() + 1e-12\n",
    "print('stepsize:',lam)\n",
    "x1 = GD(x0, lam,k)\n",
    "print(\"x:\", x1)\n",
    "print(\"Gradient\", P_grad(x1,k))\n",
    "N = Norm(x1 - x0)\n",
    "print(\"Squared Norm:\",N)\n",
    "while N > EPSILON:\n",
    "    lam = stepsize(x1,x0, k)\n",
    "    print(\"stepsize:\", lam)\n",
    "    x0 = x1\n",
    "    x1 = GD(x0, lam, k)\n",
    "    print(\"x:\", x1)\n",
    "    print(\"Gradient\", P_grad(x1,k))\n",
    "    k += 1\n",
    "    print(\"k=\", k)\n",
    "    N = Norm(x1 - x0)\n",
    "    print(\"Squared Norm:\",N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03222329044272399"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Norm([5.12295895e-09, 1.79508469e-01])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Failed $\\log$ barrier penalty method algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_func(x): return x[0]**2 + x[1]**2 + x[0] - x[1]\n",
    "def Gs(x):\n",
    "    g1, g2 = 1 - x[0] , -x[1]\n",
    "    return np.array([g1,g2])\n",
    "def P(x,k):\n",
    "    return obj_func(x) - (1/k)*np.log(-Gs(x))\n",
    "def P_grad(x,k):\n",
    "    p1 = 2*x[0] + 1 + 1/(k*(1-x[0]))\n",
    "    p2 = 2*x[1] -1 + 1/(k*x[1])\n",
    "    return np.array([p1,p2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "def obj_func(x): return x[0]**2 + x[1]**2 + x[0] - x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gs(x):\n",
    "    g1, g2 = 1 - x[0] , -x[1]\n",
    "    return np.array([g1,g2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_lim_x_test = np.array([2,1.5])\n",
    "print(obj_func(pre_lim_x_test))\n",
    "Gs(pre_lim_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P(x,k):\n",
    "    return obj_func(x) - (1/k)*np.log(-Gs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1/k)*np.log(Gs(x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_grad(x,k):\n",
    "    p1 = 2*x[0] + 1 + 1/(k*(1-x[0]))\n",
    "    p2 = 2*x[1] -1 + 1/(k*x[1])\n",
    "    return np.array([p1,p2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_grad(pre_lim_x_test,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Norm(x): return np.linalg.norm(x)\n",
    "\n",
    "def stepsize(x1, x0,k):\n",
    "    nom = np.dot(x1 - x0, P_grad(x1,k) - P_grad(x0,k))\n",
    "    denom = np.linalg.norm( P_grad(x1,k) - P_grad(x0,k) )**2\n",
    "    return nom/denom\n",
    "\n",
    "def GD(x, lam ,k):\n",
    "    return x - lam*P_grad(x,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pre_lim_x_test\n",
    "EPSILON = 1e-3\n",
    "k = 1\n",
    "# x0 = np.array([random.randrange(1,20), random.randrange(0,20)])\n",
    "x0 = x\n",
    "print(\"x:\", x0)\n",
    "print(\"Gradient\", P_grad(x0,k))\n",
    "lam = random.random() + 1e-12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1/k)*np.log(Gs(x0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gs(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = GD(x0, lam,k)\n",
    "print(\"x:\", x1)\n",
    "print(\"Gradient\", P_grad(x1,k))\n",
    "N = Norm(P_grad(x,k))\n",
    "print(\"Squared Norm:\",N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Norm(P_grad([1.0000000001,0.0000000001],k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "while N > EPSILON:\n",
    "    lam = stepsize(x1,x0, k)\n",
    "    print(\"stepsize:\", lam)\n",
    "    x0 = x1\n",
    "    x1 = GD(x0, lam, k)\n",
    "    print(\"x:\", x1)\n",
    "    print(\"Gradient\", P_grad(x1,k))\n",
    "    k += 1\n",
    "    N = Norm(P_grad(x,k))\n",
    "    print(\"Squared Norm:\",N)\n",
    "            \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIELDSIZE = 100\n",
    "NUM_X = 100\n",
    "\n",
    "X = []\n",
    "\n",
    "for i in range(FIELDSIZE):\n",
    "    x_i = np.array([random.randrange(-FIELDSIZE, FIELDSIZE), random.randrange(-FIELDSIZE, FIELDSIZE)])\n",
    "    X.append(x_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.18373729622067"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.random()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.array([random.randrange(-FIELDSIZE, FIELDSIZE), random.randrange(-FIELDSIZE, FIELDSIZE)])\n",
    "S_data = [S]\n",
    "\n",
    "def norm_func(s, x):\n",
    "    return (s[0] - x[0])**2 + (s[1] - x[1])**2\n",
    "\n",
    "norms = []\n",
    "for x in X:\n",
    "    norms.append(norm(S,x))\n",
    "\n",
    "alpha_index = np.argmax(norms)\n",
    "alpha = norms[alpha_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = [0]*len(X)\n",
    "\n",
    "def obj(s):\n",
    "    obj_norms = []\n",
    "    for x in X:\n",
    "        obj_norms.append(norm(S,x))\n",
    "    return sum(obj_norms) + alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditions(s):\n",
    "    g = [0]*len(X)\n",
    "    for i in range(len(X)):\n",
    "        g[i] = norm(s, X[i]) - alpha\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lagrange(s):\n",
    "    G = conditions(s)\n",
    "    lambda_gs = [0]*len(X)\n",
    "    for i in range(len(X)):\n",
    "        lambda_gs[i] = lambdas[i]*G[i]\n",
    "    return obj(s) + sum(lambda_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagrange(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_lagrange(s):\n",
    "    gradL = [0, 0]\n",
    "    for i in range(len(X)):\n",
    "        gradL[0] += 2*(1+lambdas[i])*(s[0]-X[i][0])\n",
    "        gradL[1] += 2*(1+lambdas[i])*(s[1]-X[i][1])\n",
    "    return np.array(gradL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = conditions(S)\n",
    "G[alpha_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_gl(s):\n",
    "    gradgL = [0,0]\n",
    "    for i in range(len(X)):\n",
    "        gradgL[0] += 2*(s[0] - X[i][0])\n",
    "        gradgL[1] += 2*(s[1] - X[i][1])\n",
    "    return np.array(gradgL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Real_norm(s): return np.linalg.norm(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(lambdaa):\n",
    "    return lambdaa - STEPSIZE*grad_gl(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Backtrack(l1, l2):\n",
    "    STEPSIZE = np.dot(l2 - l1, 2*(S - ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = []\n",
    "L1 = random.randrange(1e6)\n",
    "L2 = L1 - 5\n",
    "while Real_norm(grad_lagrange(S)) > 10:\n",
    "    STEPSIZE = Backtrack(L1, L2)\n",
    "    lambdas[alpha_index]  = step(lambdas[alpha_index])\n",
    "    teste.append(lambdas[alpha_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(teste)), teste)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Real_norm(S - np.array(grad_lagrange(S)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_lagrange(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_lagrange(S - 10 * np.array(grad_lagrange(S)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPSIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.randrange(1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
