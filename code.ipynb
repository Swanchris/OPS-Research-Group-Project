{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\mathcal{l}_2$ penalty method algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def alpha(k): return 2**k\n",
    "# def xplus(x): return max(x,0)\n",
    "# def Norm(x): return np.linalg.norm(x)\n",
    "\n",
    "# def obj_func(x): return x[0]**2 + x[1]**2 + x[0] - x[1]\n",
    "# def G(x): return np.array([1 -x[0], -x[1] ])\n",
    "# def P(x,k): return obj_func(x) + (alpha(k)/2)*xplus(G(x)[0])**2 + (alpha(k)/2)*xplus(G(x)[1])**2\n",
    "# def P_grad(x,k):\n",
    "#     g1 = 2*x[0] + 1 - alpha(k)*xplus(1-x[0])\n",
    "#     g2 = 2*x[1] - 1 - alpha(k)*xplus(-x[1])\n",
    "#     return np.array( [ g1 , g2 ] )\n",
    "# def stepsize(x1, x0,k): # Barzilai-Borwein step-size (quasi-newton origin)\n",
    "#     nom = np.dot(x1 - x0, P_grad(x1,k) - P_grad(x0,k))\n",
    "#     denom = np.linalg.norm( P_grad(x1,k) - P_grad(x0,k) )**2\n",
    "#     return nom/denom\n",
    "# # Note: Direction is just steepest descent\n",
    "# def GD(x, lam ,k):\n",
    "#     return x - lam*P_grad(x,k)\n",
    "# def Descent(x, init_step, EPSILON):\n",
    "#     x0 = np.array(x)\n",
    "#     k = 1\n",
    "#     x_list = [x0]\n",
    "#     lam = init_step\n",
    "#     x1 = GD(x0, lam ,k)\n",
    "#     x_list.append(x1)\n",
    "#     N = Norm(x1 - x0)\n",
    "#     Norm_list = [N]\n",
    "    \n",
    "#     while N > EPSILON:\n",
    "#         lam = stepsize(x1, x0, k)\n",
    "#         x0 = x1\n",
    "#         x1 = GD(x0, lam, k)\n",
    "#         x_list.append(x1)\n",
    "#         N = Norm(x1 - x0)\n",
    "#         Norm_list = [N]\n",
    "#         k += 1\n",
    "    \n",
    "#     return np.array([ x_list, Norm_list ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The real deal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(k): return 2**k\n",
    "def xplus(x): return max(x,0)\n",
    "def Norm(x): return np.linalg.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIELDSIZE = 100\n",
    "SCALE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate a squared norm of s - x, as in our obj func and constraints\n",
    "def norm_func(s, x):\n",
    "    return (s[0] - x[0])**2 + (s[1] - x[1])**2\n",
    "\n",
    "# create a list of the squared euclidean distance from s to each point x in X\n",
    "def X_norms_sqrd(s, X): return [norm_func(s,i) for i in X]\n",
    "\n",
    "# find the largest distance\n",
    "def beta(s, X): return max(X_norms_sqrd(s, X))\n",
    "\n",
    "# create an objective function\n",
    "def obj_func(s,X, b): \n",
    "    x_list = X_norms_sqrd(s,X)\n",
    "    return sum(x_list) + beta(s, x_list)\n",
    "\n",
    "# create the g constraints\n",
    "def G(s,X, b): return [ norm_func(s, X[i]) - b for i in range(len(X))]\n",
    "\n",
    "# l2-penalty function\n",
    "def P(s,X,k, b): \n",
    "    return obj_func(s,X, b) + (alpha(k)/2)*sum([ xplus(G(s,X, b)[i])**2 for i in range(len(X)) ])\n",
    "\n",
    "def P_grad(s,X,k, b):\n",
    "    s_minus_x_0 = np.array([ s[0] - X[i][0] for i in range(len(X)) ])\n",
    "    G_sum_0 = np.array([ (s[0] - X[i][0])**2 - b for i in range(len(X))])\n",
    "    mult_terms_0 = [xplus(s_minus_x_0[i] * G_sum_0[i]) for i in range(len(X))]\n",
    "    \n",
    "    g1 = 2*sum(s_minus_x_0) + 2*alpha(k)*sum( mult_terms_0)\n",
    "    \n",
    "    s_minus_x_1 = np.array([ s[1] - X[i][1] for i in range(len(X)) ])\n",
    "    G_sum_1 = np.array([ (s[1] - X[i][1])**2 - b for i in range(len(X))])\n",
    "    mult_terms_1 = [xplus(s_minus_x_1[i] * G_sum_1[i]) for i in range(len(X))]\n",
    "    \n",
    "    g2 = 2*sum(s_minus_x_1) + 2*alpha(k)*sum( mult_terms_1)\n",
    "    \n",
    "    return np.array( [g1 , g2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepsize(s1, s0, X, k, b): # Barzilai-Borwein step-size (quasi-newton origin)\n",
    "    nom = np.dot(s1 - s0, P_grad(s1, X ,k, b) - P_grad(s0, X ,k, b))\n",
    "    denom = np.linalg.norm( P_grad(s1, X ,k, b) - P_grad(s0, X ,k, b) )**2\n",
    "    return nom/denom\n",
    "# Note: Direction is just steepest descent\n",
    "def GD(s, X, lam ,k, b):\n",
    "    return s - lam*P_grad(s, X ,k, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate FIELDSIZE random pts in R^2 \\in (0,SCALE)\n",
    "X_points = [ [ random.random()*SCALE, random.random()*SCALE ] for i in range(FIELDSIZE) ] \n",
    "\n",
    "# generate an inital point S in the plain of X\n",
    "S_0 = [ random.random()*SCALE, random.random()*SCALE ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Descent(s, X, init_step, EPSILON):\n",
    "    b = beta(s, X)\n",
    "    s0 = np.array(s)\n",
    "    k = 1\n",
    "    s_list = [s0]\n",
    "    lam = init_step\n",
    "    s1 = GD(s0, X, lam ,k, b)\n",
    "    s_list.append(s1)\n",
    "    N = Norm(s1 - s0)\n",
    "    Norm_list = [N]\n",
    "\n",
    "    while N > EPSILON:\n",
    "        b = beta(s, X)\n",
    "        lam = stepsize(s1, s0, X, k, b)\n",
    "        s0 = s1\n",
    "        s1 = GD(s0, X, lam, k, b)\n",
    "        s_list.append(s1)\n",
    "        N = Norm(s1 - s0)\n",
    "        Norm_list.append(N)\n",
    "        k += 1\n",
    "    \n",
    "    return np.array([ s_list, Norm_list ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-d447413cee51>:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array([ s_list, Norm_list ])\n"
     ]
    }
   ],
   "source": [
    "TEST = Descent( np.array([5,5]), X_points, 0.1, 1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-14431.15577977 -15037.19128954]\n"
     ]
    }
   ],
   "source": [
    "print(TEST[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29131319.599834677, 27744116.78556115, 1387266.339500669, 825877.2735114882, 138970.62535451006, 686906.648156976, 659176.68190289, 13042.014208790879, 646134.6676941083, 642954.4048315064, 1578.4203559852206, 641375.9844755715, 640982.5895626125, 196.5165421864754, 640786.0730200945, 640736.9627114272, 24.552331554490344, 640712.4103730893, 640706.2725852696, 3.068849811778863, 640703.2037124294, 640702.4365050218, 0.38360301453992096, 640702.0525706881, 640701.9566707376, 0.04794992337829424, 640701.9051178097, 640701.8931217474, 0.005993186797801723, 640701.8554891133, 640701.8532459622, 0.0007485420795787012, 640701.8240337617, 640701.8232423923, 9.349972430732443e-05, 640703.2167873153, 640702.2464021764, 1.2111174022782275e-05, 640695.2583022567, 640669.3796127995, 1.2711830591059033e-06, 640716.5906528016, 639724.5849707633, 9.042237511448706e-07, 639867.6972125707, 608020.0841038404, 4.8112953989037895e-09, 585455.6131249075, 22389.061023333867, 20912.260233741847, 2.5724394843074972e-12]\n"
     ]
    }
   ],
   "source": [
    "print(TEST[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([5, 5]),\n",
       " array([-18813303.61418309, -18279936.12358874]),\n",
       " array([-540913.76555511,  525588.76432316]),\n",
       " array([-540479.3486193 ,  525588.76432316]),\n",
       " array([-4.46068764e+01,  5.25588764e+05]),\n",
       " array([4.67993157e+01, 5.25588764e+05]),\n",
       " array([6.06333557e+01, 5.25588764e+05]),\n",
       " array([7.77938815e+01, 5.25588764e+05]),\n",
       " array([8.55249123e+01, 5.25588764e+05]),\n",
       " array([8.98806055e+01, 5.25588764e+05]),\n",
       " array([9.28265094e+01, 5.25588764e+05]),\n",
       " array([9.48511874e+01, 5.25588764e+05]),\n",
       " array([9.59237685e+01, 5.25588764e+05]),\n",
       " array([9.75514655e+01, 5.25588764e+05]),\n",
       " array([9.84785897e+01, 5.25588764e+05]),\n",
       " array([9.84785897e+01, 5.25588764e+05]),\n",
       " array([    45.01809684, -18225.04983659]),\n",
       " array([ 66029.40905911, 517467.6678743 ]),\n",
       " array([ 66029.40906681, 517467.66793468]),\n",
       " array([47.21680164, 50.25000892]),\n",
       " array([291686.16227376, 292240.01717069]),\n",
       " array([291688.45787011, 292242.31712443]),\n",
       " array([46.81436524, 47.09422211]),\n",
       " array([284354.04520799, 299213.5718173 ]),\n",
       " array([284354.32843004, 299213.86984188]),\n",
       " array([46.81437692, 47.09423419]),\n",
       " array([284354.39930672, 299213.9442807 ]),\n",
       " array([284354.43470957, 299213.98153387]),\n",
       " array([46.81412175, 47.09396568]),\n",
       " array([284354.43073489, 299214.00303514]),\n",
       " array([284354.43516015, 299214.00769169]),\n",
       " array([46.81710766, 47.09710765]),\n",
       " array([284354.58640105, 299213.86617868]),\n",
       " array([284354.58695435, 299213.8667609 ]),\n",
       " array([46.87453825, 47.15753977]),\n",
       " array([284357.50104174, 299211.0976346 ]),\n",
       " array([284357.50111124, 299211.09770773]),\n",
       " array([46.77928883, 47.05731299]),\n",
       " array([284352.69743071, 299215.66277606]),\n",
       " array([284352.69743933, 299215.66278513]),\n",
       " array([46.67022962, 46.94255129]),\n",
       " array([284347.35704623, 299220.73769052]),\n",
       " array([284347.3570473 , 299220.73769164]),\n",
       " array([44.15550059, 44.29625951]),\n",
       " array([284757.24776868, 298830.15275561]),\n",
       " array([284757.24776879, 298830.15275572]),\n",
       " array([289.94643652, 302.24378919]),\n",
       " array([46.81436939, 47.09422626]),\n",
       " array([289.60201268, 302.57110591]),\n",
       " array([289.60201268, 302.57110591])]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_ax = [X_points[i][0] for i in range(len(X_points))]\n",
    "y_ax = [X_points[i][1] for i in range(len(X_points))]\n",
    "plt.scatter(x_ax, y_ax, c ='y')\n",
    "plt.scatter(TEST[0][-3][0],TEST[0][-3][1], c = 'b' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([289.60201268, 302.57110591])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48557.52865815, 51095.37592916])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_grad(TEST[0][-1], X_points, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [5 5]\n",
      "Gradient [11  9]\n",
      "stepsize: 0.1\n",
      "x: [3.9 4.1]\n",
      "Gradient [8.8 7.2]\n",
      "Squared Norm: 1.42126704035519\n",
      "stepsize: 0.5000000000000002\n",
      "x: [-0.5  0.5]\n",
      "Gradient [-3.00000000e+00 -3.55271368e-15]\n",
      "k= 2\n",
      "Squared Norm: 5.6850681614207605\n",
      "stepsize: 0.33608978145304175\n",
      "x: [1.51653869 0.5       ]\n",
      "Gradient [ 4.03307738e+00 -1.11022302e-15]\n",
      "k= 3\n",
      "Squared Norm: 2.016538688718255\n",
      "stepsize: 0.1257736516357206\n",
      "x: [1.00928382 0.5       ]\n",
      "Gradient [ 3.01856764e+00 -7.77156117e-16]\n",
      "k= 4\n",
      "Squared Norm: 0.5072548690896048\n",
      "stepsize: 0.5\n",
      "x: [-0.5  0.5]\n",
      "Gradient [-24.   0.]\n",
      "k= 5\n",
      "Squared Norm: 1.509283819628648\n",
      "stepsize: 0.02958303005095145\n",
      "x: [0.91998544 0.5       ]\n",
      "Gradient [0.27950504 0.        ]\n",
      "k= 6\n",
      "Squared Norm: 1.4199854424456697\n",
      "stepsize: 0.015151515151515152\n",
      "x: [0.95454545 0.5       ]\n",
      "Gradient [2.66453526e-15 0.00000000e+00]\n",
      "k= 7\n",
      "Squared Norm: 0.034560012099784876\n",
      "stepsize: 0.007692307692307694\n",
      "x: [0.97692308 0.5       ]\n",
      "Gradient [-3.55271368e-15  0.00000000e+00]\n",
      "k= 8\n",
      "Squared Norm: 0.022377622377622308\n",
      "stepsize: 0.003875968992248062\n",
      "x: [0.98837209 0.5       ]\n",
      "Gradient [-5.32907052e-15  0.00000000e+00]\n",
      "k= 9\n",
      "Squared Norm: 0.0114490161001789\n",
      "stepsize: 0.0019455252918287938\n",
      "x: [0.99416342 0.5       ]\n",
      "Gradient [1.0658141e-14 0.0000000e+00]\n",
      "k= 10\n",
      "Squared Norm: 0.005791331101257846\n",
      "stepsize: 0.0009746588693957116\n",
      "x: [0.99707602 0.5       ]\n",
      "Gradient [2.84217094e-14 0.00000000e+00]\n",
      "k= 11\n",
      "Squared Norm: 0.002912599267299254\n",
      "stepsize: 0.0004878048780487805\n",
      "x: [0.99853659 0.5       ]\n",
      "Gradient [-2.66453526e-15  0.00000000e+00]\n",
      "k= 12\n",
      "Squared Norm: 0.0014605619740407638\n",
      "stepsize: 0.00024402147388970225\n",
      "x: [0.99926794 0.5       ]\n",
      "Gradient [1.70530257e-13 0.00000000e+00]\n",
      "k= 13\n",
      "Squared Norm: 0.0007313502124772775\n",
      "stepsize: 0.000122040517451794\n",
      "x: [0.99963388 0.5       ]\n",
      "Gradient [1.0658141e-14 0.0000000e+00]\n",
      "k= 14\n",
      "Squared Norm: 0.0003659428693136846\n",
      "stepsize: 6.102770657878677e-05\n",
      "x: [0.99981692 0.5       ]\n",
      "Gradient [8.8817842e-16 0.0000000e+00]\n",
      "k= 15\n",
      "Squared Norm: 0.00018303843261902042\n",
      "stepsize: 3.0515715593530668e-05\n",
      "x: [0.99990845 0.5       ]\n",
      "Gradient [-6.82121026e-13  0.00000000e+00]\n",
      "k= 16\n",
      "Squared Norm: 9.153597295574745e-05\n",
      "stepsize: 1.525832341542311e-05\n",
      "x: [0.99995423 0.5       ]\n",
      "Gradient [-8.52651283e-14  0.00000000e+00]\n",
      "k= 17\n",
      "Squared Norm: 4.577217653434218e-05\n",
      "stepsize: 7.629278117704503e-06\n",
      "x: [0.99997711 0.5       ]\n",
      "Gradient [-1.0658141e-14  0.0000000e+00]\n",
      "k= 18\n",
      "Squared Norm: 2.288713589315705e-05\n",
      "stepsize: 3.814668162016586e-06\n",
      "x: [0.99998856 0.5       ]\n",
      "Gradient [-1.33226763e-15  0.00000000e+00]\n",
      "k= 19\n",
      "Squared Norm: 1.1443829867063826e-05\n",
      "stepsize: 1.9073413568826414e-06\n",
      "x: [0.99999428 0.5       ]\n",
      "Gradient [-1.45519152e-11  0.00000000e+00]\n",
      "k= 20\n",
      "Squared Norm: 5.721980415374084e-06\n",
      "stepsize: 9.536724974203157e-07\n",
      "x: [0.99999714 0.5       ]\n",
      "Gradient [1.09139364e-11 0.00000000e+00]\n",
      "k= 21\n",
      "Squared Norm: 2.8610065784251404e-06\n",
      "stepsize: 4.7683670345620785e-07\n",
      "x: [0.99999857 0.5       ]\n",
      "Gradient [2.72848411e-12 0.00000000e+00]\n",
      "k= 22\n",
      "Squared Norm: 1.430507381883217e-06\n",
      "stepsize: 2.38418465414779e-07\n",
      "x: [0.99999928 0.5       ]\n",
      "Gradient [6.82121026e-13 0.00000000e+00]\n",
      "k= 23\n",
      "Squared Norm: 7.15254714123148e-07\n",
      "stepsize: 1.192092611290786e-07\n",
      "x: [0.99999964 0.5       ]\n",
      "Gradient [1.70530257e-13 0.00000000e+00]\n",
      "k= 24\n",
      "Squared Norm: 3.576276128569589e-07\n",
      "stepsize: 5.9604637669964114e-08\n",
      "x: [0.99999982 0.5       ]\n",
      "Gradient [4.26325641e-14 0.00000000e+00]\n",
      "k= 25\n",
      "Squared Norm: 1.7881387037732566e-07\n",
      "stepsize: 2.980232061133858e-08\n",
      "x: [0.99999991 0.5       ]\n",
      "Gradient [1.0658141e-14 0.0000000e+00]\n",
      "k= 26\n",
      "Squared Norm: 8.940695117587438e-08\n",
      "stepsize: 1.4901160749758461e-08\n",
      "x: [0.99999996 0.5       ]\n",
      "Gradient [2.66453526e-15 0.00000000e+00]\n",
      "k= 27\n",
      "Squared Norm: 4.470347958474008e-08\n",
      "stepsize: 7.4505804859015265e-09\n",
      "x: [0.99999998 0.5       ]\n",
      "Gradient [8.8817842e-16 0.0000000e+00]\n",
      "k= 28\n",
      "Squared Norm: 2.2351740791570762e-08\n",
      "stepsize: 3.7252902707063384e-09\n",
      "x: [0.99999999 0.5       ]\n",
      "Gradient [7.4505806e-09 0.0000000e+00]\n",
      "k= 29\n",
      "Squared Norm: 1.1175870673341137e-08\n",
      "stepsize: 1.8626451422920633e-09\n",
      "x: [0.99999999 0.5       ]\n",
      "Gradient [-1.11758709e-08  0.00000000e+00]\n",
      "k= 30\n",
      "Squared Norm: 5.587935336670569e-09\n",
      "stepsize: 9.313225728807549e-10\n",
      "x: [1.  0.5]\n",
      "Gradient [-5.58793545e-09  0.00000000e+00]\n",
      "k= 31\n",
      "Squared Norm: 2.7939677238464355e-09\n",
      "stepsize: 4.656612868740584e-10\n",
      "x: [1.  0.5]\n",
      "Gradient [-2.79396772e-09  0.00000000e+00]\n",
      "k= 32\n",
      "Squared Norm: 1.3969838619232178e-09\n",
      "stepsize: 2.328306435454494e-10\n",
      "x: [1.  0.5]\n",
      "Gradient [-1.39698386e-09  0.00000000e+00]\n",
      "k= 33\n",
      "Squared Norm: 6.984919309616089e-10\n",
      "stepsize: 1.1641532179982976e-10\n",
      "x: [1.  0.5]\n",
      "Gradient [-6.98491931e-10  0.00000000e+00]\n",
      "k= 34\n",
      "Squared Norm: 3.4924596548080444e-10\n",
      "stepsize: 5.8207660906691144e-11\n",
      "x: [1.  0.5]\n",
      "Gradient [-3.49245965e-10  0.00000000e+00]\n",
      "k= 35\n",
      "Squared Norm: 1.7462298274040222e-10\n",
      "stepsize: 2.9103830455039638e-11\n",
      "x: [1.  0.5]\n",
      "Gradient [-1.74622983e-10  0.00000000e+00]\n",
      "k= 36\n",
      "Squared Norm: 8.731149137020111e-11\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([5,5])\n",
    "EPSILON = 1e-10\n",
    "k = 1\n",
    "# x0 = np.array([random.randrange(1,20), random.randrange(0,20)])\n",
    "print(\"x:\", x0)\n",
    "print(\"Gradient\", P_grad(x0,k))\n",
    "lam = 0.1 #random.random() + 1e-12\n",
    "print('stepsize:',lam)\n",
    "x1 = GD(x0, lam,k)\n",
    "print(\"x:\", x1)\n",
    "print(\"Gradient\", P_grad(x1,k))\n",
    "N = Norm(x1 - x0)\n",
    "print(\"Squared Norm:\",N)\n",
    "while N > EPSILON:\n",
    "    lam = stepsize(x1,x0, k)\n",
    "    print(\"stepsize:\", lam)\n",
    "    x0 = x1\n",
    "    x1 = GD(x0, lam, k)\n",
    "    print(\"x:\", x1)\n",
    "    print(\"Gradient\", P_grad(x1,k))\n",
    "    k += 1\n",
    "    print(\"k=\", k)\n",
    "    N = Norm(x1 - x0)\n",
    "    print(\"Squared Norm:\",N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03222329044272399"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Norm([5.12295895e-09, 1.79508469e-01])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Failed $\\log$ barrier penalty method algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_func(x): return x[0]**2 + x[1]**2 + x[0] - x[1]\n",
    "def Gs(x):\n",
    "    g1, g2 = 1 - x[0] , -x[1]\n",
    "    return np.array([g1,g2])\n",
    "def P(x,k):\n",
    "    return obj_func(x) - (1/k)*np.log(-Gs(x))\n",
    "def P_grad(x,k):\n",
    "    p1 = 2*x[0] + 1 + 1/(k*(1-x[0]))\n",
    "    p2 = 2*x[1] -1 + 1/(k*x[1])\n",
    "    return np.array([p1,p2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "def obj_func(x): return x[0]**2 + x[1]**2 + x[0] - x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gs(x):\n",
    "    g1, g2 = 1 - x[0] , -x[1]\n",
    "    return np.array([g1,g2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_lim_x_test = np.array([2,1.5])\n",
    "print(obj_func(pre_lim_x_test))\n",
    "Gs(pre_lim_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P(x,k):\n",
    "    return obj_func(x) - (1/k)*np.log(-Gs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1/k)*np.log(Gs(x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_grad(x,k):\n",
    "    p1 = 2*x[0] + 1 + 1/(k*(1-x[0]))\n",
    "    p2 = 2*x[1] -1 + 1/(k*x[1])\n",
    "    return np.array([p1,p2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_grad(pre_lim_x_test,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Norm(x): return np.linalg.norm(x)\n",
    "\n",
    "def stepsize(x1, x0,k):\n",
    "    nom = np.dot(x1 - x0, P_grad(x1,k) - P_grad(x0,k))\n",
    "    denom = np.linalg.norm( P_grad(x1,k) - P_grad(x0,k) )**2\n",
    "    return nom/denom\n",
    "\n",
    "def GD(x, lam ,k):\n",
    "    return x - lam*P_grad(x,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pre_lim_x_test\n",
    "EPSILON = 1e-3\n",
    "k = 1\n",
    "# x0 = np.array([random.randrange(1,20), random.randrange(0,20)])\n",
    "x0 = x\n",
    "print(\"x:\", x0)\n",
    "print(\"Gradient\", P_grad(x0,k))\n",
    "lam = random.random() + 1e-12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1/k)*np.log(Gs(x0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gs(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = GD(x0, lam,k)\n",
    "print(\"x:\", x1)\n",
    "print(\"Gradient\", P_grad(x1,k))\n",
    "N = Norm(P_grad(x,k))\n",
    "print(\"Squared Norm:\",N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Norm(P_grad([1.0000000001,0.0000000001],k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "while N > EPSILON:\n",
    "    lam = stepsize(x1,x0, k)\n",
    "    print(\"stepsize:\", lam)\n",
    "    x0 = x1\n",
    "    x1 = GD(x0, lam, k)\n",
    "    print(\"x:\", x1)\n",
    "    print(\"Gradient\", P_grad(x1,k))\n",
    "    k += 1\n",
    "    N = Norm(P_grad(x,k))\n",
    "    print(\"Squared Norm:\",N)\n",
    "            \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIELDSIZE = 100\n",
    "NUM_X = 100\n",
    "\n",
    "X = []\n",
    "\n",
    "for i in range(FIELDSIZE):\n",
    "    x_i = np.array([random.randrange(-FIELDSIZE, FIELDSIZE), random.randrange(-FIELDSIZE, FIELDSIZE)])\n",
    "    X.append(x_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.18373729622067"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.random()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.array([random.randrange(-FIELDSIZE, FIELDSIZE), random.randrange(-FIELDSIZE, FIELDSIZE)])\n",
    "S_data = [S]\n",
    "\n",
    "def norm_func(s, x):\n",
    "    return (s[0] - x[0])**2 + (s[1] - x[1])**2\n",
    "\n",
    "norms = []\n",
    "for x in X:\n",
    "    norms.append(norm(S,x))\n",
    "\n",
    "alpha_index = np.argmax(norms)\n",
    "alpha = norms[alpha_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = [0]*len(X)\n",
    "\n",
    "def obj(s):\n",
    "    obj_norms = []\n",
    "    for x in X:\n",
    "        obj_norms.append(norm(S,x))\n",
    "    return sum(obj_norms) + alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditions(s):\n",
    "    g = [0]*len(X)\n",
    "    for i in range(len(X)):\n",
    "        g[i] = norm(s, X[i]) - alpha\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lagrange(s):\n",
    "    G = conditions(s)\n",
    "    lambda_gs = [0]*len(X)\n",
    "    for i in range(len(X)):\n",
    "        lambda_gs[i] = lambdas[i]*G[i]\n",
    "    return obj(s) + sum(lambda_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagrange(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_lagrange(s):\n",
    "    gradL = [0, 0]\n",
    "    for i in range(len(X)):\n",
    "        gradL[0] += 2*(1+lambdas[i])*(s[0]-X[i][0])\n",
    "        gradL[1] += 2*(1+lambdas[i])*(s[1]-X[i][1])\n",
    "    return np.array(gradL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = conditions(S)\n",
    "G[alpha_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_gl(s):\n",
    "    gradgL = [0,0]\n",
    "    for i in range(len(X)):\n",
    "        gradgL[0] += 2*(s[0] - X[i][0])\n",
    "        gradgL[1] += 2*(s[1] - X[i][1])\n",
    "    return np.array(gradgL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Real_norm(s): return np.linalg.norm(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(lambdaa):\n",
    "    return lambdaa - STEPSIZE*grad_gl(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Backtrack(l1, l2):\n",
    "    STEPSIZE = np.dot(l2 - l1, 2*(S - ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = []\n",
    "L1 = random.randrange(1e6)\n",
    "L2 = L1 - 5\n",
    "while Real_norm(grad_lagrange(S)) > 10:\n",
    "    STEPSIZE = Backtrack(L1, L2)\n",
    "    lambdas[alpha_index]  = step(lambdas[alpha_index])\n",
    "    teste.append(lambdas[alpha_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(teste)), teste)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Real_norm(S - np.array(grad_lagrange(S)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_lagrange(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_lagrange(S - 10 * np.array(grad_lagrange(S)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPSIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.randrange(1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
